# Workshop 9/12

#### How we should choose K in K Nearest Neighbor Classification:

Choice of K is somewhat driven by the end application as well as the dataset. One can use KF Cross Validation for testing performance of KNN with some various quantities of neighbours and finding the optimum `k`. I do think we should choose `k` large enough that noise in the data is minimized and small enough so the samples of the other classes are not included. 
